# NLP_PapersReview
This is git rep for some of my short reviews on those top NLP papers. If there is anything wrong, please help to indicate it.

##

[BART](./BART:%20Denoising%20Sequence-to-Sequence%20Pre-training%20for%20Natural%20Language%20Generation,%20Translation,%20and%20Comprehension.md)

[RoBERTa](./RoBERTa:%20A%20Robustly%20Optimized%20BERT%20Pretraining%20Approach.md)
